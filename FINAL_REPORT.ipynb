{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2e1755-dec6-415f-ab0d-3a83f78d1f3e",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7873555-89d0-4f2c-bc24-57f2361ebd1c",
   "metadata": {},
   "source": [
    "Humaira Halim (hbh4bv@virginia.edu) DS 5001 Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400adbd2-7273-4cda-b58c-a261e63fcaa6",
   "metadata": {},
   "source": [
    "Code for report worked in collaboration with Nikita Amanna and Nicholas Kalinowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417256f2-fc16-4bc8-aa29-32e6eb797479",
   "metadata": {},
   "source": [
    "## Introduction. \n",
    "*Describe the nature of your corpus and the question(s) you've asked of the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21b5b7-5ed7-445e-9664-5733c6e8af07",
   "metadata": {},
   "source": [
    "According to the Encyclopedia Brittanica, the genre of science fiction is defined as \"a form of fiction that deals principally with the impact of actual or imagined science upon society or individuals\" (2023). Science fiction is a relatively modern subject in written literature; forming alongside the socioeconomic changes of the Industrial Revolution, the West is accredited for its origins as writers began contemplating the consequences of technological developments. Combining text analysis with 19th-20th century Science Fiction offers an anthropological glimpse into what the visionary's imagined as the consequences of post-Industrial Revolution. \n",
    "\n",
    "For my project, I have sourced 6 popular scifi novels of the 19th-20th century from American authors. I was interested in what these authors imagined for the future of science, humored by my reality as a data scientist two centuries later. The text models used in this report to characterize my corpora are Principal Components (PCA), Topic Models (LDA), Word Embeddings (word2vec), and Sentiment Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbffb8e-7b3e-42e0-a07e-fd7fa8331cb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Data. \n",
    "*Provide a description of all relativant source files and describe the following features for each source file:*\n",
    "\n",
    "*Provenance: Where did they come from? Describe the website or other source and provide relevant URLs.*\n",
    "*Location: Provide a link to the source files in UVA Box.*\n",
    "*Description: What is the general subject matter of the corpus? How many observations are there? What is the average document length?*\n",
    "*Format: A description of both the file formats of the source files, e.g., plaintext, XML, CSV, etc., and the internal structure where applicable. For - example, if XML then specify document type (e.g., TEI or XHTML).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba4ece-4720-47df-bbaf-b0bbbd3c8934",
   "metadata": {},
   "source": [
    "The six American scifi books I have selected for analysis are: \n",
    "* *Looking Backward* (1887) by Edward Bellamy\n",
    "* *The Iron Heel* (1998) by Jack London\n",
    "* *A Voyage to the Moon* (1827) by George Tucker  \n",
    "* *The Variable Man* (1953) by Philip K Dick \n",
    "* *The Brick Moon* (1869) by Edward Everett Hale  \n",
    "* *Youth* (1952) by Isaac Asimov \n",
    "\n",
    "The novels in my corpus were all sourced from Project Gutenberg, an online archive dedicated to digitizing and preserving older works. The link to Project Guntenberg can be found [here.](https://www.gutenberg.org/) Additionally, access to the raw .txt files of my corpus via UVA box can be found [here.](https://www.dropbox.com/scl/fo/vo4jx7bw8d0ybyiy9bhdm/h?dl=0&rlkey=u49a6y1hb67ic1nnypw554ahk)\n",
    "\n",
    "Below is a basic summary chart of these observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1ba93-b6dc-4055-9a4c-90f7fd51e5a2",
   "metadata": {},
   "source": [
    "![1.png](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1dc5f-c895-423f-86aa-e89ecacb09e8",
   "metadata": {},
   "source": [
    "The average length of the books within my corpora are about 19 chapters, with a mean of 50,200 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b940d3-f6c5-4a7f-8e6a-799007961e8e",
   "metadata": {},
   "source": [
    "## Data Model. \n",
    "*Describe the analytical tables you generated in the process of tokenization, annotation, and analysis of your corpus. You provide a list of tables with field names and their definition, along with URLs to each associated CSV file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216cd0f-41e2-4828-bc9c-8787b4c73a6c",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "For the PCA, I needed to generate a bag of words and tfidf. The TFIDF table is an extension of an implied DOC table, where each doc is an observation (particularly a chapter in this case). PCA results in two tables: [loadings](https://github.com/Humairabh/DS5001FinalProject/blob/a11f204dde1c94c07d64c48649460213195c94b3/Data%20Files/american_loadings.csv) (language model) and [docs and components](https://github.com/Humairabh/DS5001FinalProject/blob/main/Data%20Files/american_components.csv) (which replaces the original document-term matrix with a reduced version). \n",
    "\n",
    "#### LDA\n",
    "\n",
    "For topic models, I uses Scikit-Learn's CountVectorizer function to convert the F1 corpus into a document-term (aka DTM) vector space of word counts. From there, I could use Scikit-Learn's LatentDirichletAllocation algorithm to extract the [THETA](https://github.com/Humairabh/DS5001FinalProject/blob/a11f204dde1c94c07d64c48649460213195c94b3/Data%20Files/american_theta.csv) (doctopic where counts get normalized into PDFs) and [PHI](https://github.com/Humairabh/DS5001FinalProject/blob/a11f204dde1c94c07d64c48649460213195c94b3/Data%20Files/phi.csv) (topicword where counts get normalized into PDFs) tables. I also created a [TOPICS](https://github.com/Humairabh/DS5001FinalProject/blob/a11f204dde1c94c07d64c48649460213195c94b3/Data%20Files/topics.csv) table:\n",
    "![topic.png](topic.png)\n",
    "\n",
    "this table includes a list of the topics (0-8), most associated words by each topic, document weight and term frequency.\n",
    "\n",
    "#### Word Embeddings (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599702ac-be6e-4473-ad48-c37c5e9f17bb",
   "metadata": {},
   "source": [
    "## Exploration. \n",
    "\n",
    "*Describe each of your explorations, such as PCA and topic models. For each, include the relevant parameters and hyperparemeters used to generate each model and visualization. For your visualizations, you should use at least three (but likely more) of the following visualization types:*\n",
    "\n",
    "*Hierarchical cluster diagrams*\n",
    "\n",
    "*Heatmaps showing correlations*\n",
    "\n",
    "*Scatter plots*\n",
    "\n",
    "*KDE plots*\n",
    "\n",
    "*Dispersion plots*\n",
    "\n",
    "*t-SNE plots*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e89380-7f45-46a0-90dc-594098f4b17d",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "#### LDA\n",
    "The LDA model attempts to estimate probability distributions for topics in documents plus words in topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d86fe-0f86-4f66-b09f-36de39516109",
   "metadata": {},
   "source": [
    "## Interpretation. \n",
    "\n",
    "*Provide your interpretation of the results of exploration, and any conclusion if you are comfortable making them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50728e7-f086-4496-b977-942e59f0d1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5129095a-1fdf-4175-a59b-70b2d14316aa",
   "metadata": {},
   "source": [
    "## Resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7934f-7f22-4fc1-9b8c-ae37010524b2",
   "metadata": {},
   "source": [
    "Dropbox link: https://www.dropbox.com/scl/fo/vo4jx7bw8d0ybyiy9bhdm/h?dl=0&rlkey=u49a6y1hb67ic1nnypw554ahk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b8a4e-170a-469c-b011-ed2c19e42d85",
   "metadata": {},
   "source": [
    "All code resourced from class labs and lecture: https://github.com/ontoligent/DS5001-2023-01-R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce348e-ae11-41de-a3e9-1b37988eea24",
   "metadata": {},
   "source": [
    "“Science Fiction.” Encyclopædia Britannica, Encyclopædia Britannica, Inc., 21 Apr. 2023, https://www.britannica.com/art/science-fiction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
